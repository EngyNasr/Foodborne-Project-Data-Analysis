{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioblend.galaxy import GalaxyInstance\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import requests\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add galaxy API key\n",
    "Add `GALAXY_API_KEY` from `https://usegalaxy.eu/user/api_key` via `export GALAXY_API_KEY=\"<key>\"` or `%env  GALAXY_API_KEY=<key>` in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GALAXY_API_KEY=bd61afb0a73cdb2e681e3caf8d162221\n"
     ]
    }
   ],
   "source": [
    "%env GALAXY_API_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too many datasets with that name\n"
     ]
    }
   ],
   "source": [
    "history_id = \"737d864aaf9b7c41\"\n",
    "collection_name = \"VFs\"\n",
    "\n",
    "gi = GalaxyInstance(url='https://usegalaxy.eu/', key=os.environ['GALAXY_API_KEY'])\n",
    "\n",
    "datasets = gi.datasets.get_datasets(name = collection_name, history_id = history_id)\n",
    "\n",
    "#print(datasets)\n",
    "\n",
    "#fetch collection by name\n",
    "if len(datasets) > 1:\n",
    "    print(\"too many datasets with that name\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    if dataset['history_content_type']=='dataset_collection': #get only collections\n",
    "        if dataset['job_state_summary']['all_jobs'] == dataset['job_state_summary']['ok']: #get only collections where all jobs are ok\n",
    "            dataset_collection_id = dataset[\"id\"]\n",
    "\n",
    "\n",
    "# get data of the elements in the collection\n",
    "collection = gi.dataset_collections.show_dataset_collection(dataset_collection_id = dataset_collection_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_file_000000.txt\n",
      "split_file_000001.txt\n",
      "split_file_000002.txt\n",
      "split_file_000003.txt\n",
      "split_file_000004.txt\n",
      "split_file_000005.txt\n",
      "split_file_000006.txt\n",
      "split_file_000007.txt\n",
      "split_file_000008.txt\n",
      "split_file_000009.txt\n",
      "split_file_000010.txt\n",
      "split_file_000011.txt\n",
      "split_file_000012.txt\n",
      "split_file_000013.txt\n",
      "split_file_000014.txt\n",
      "split_file_000015.txt\n",
      "split_file_000016.txt\n",
      "split_file_000017.txt\n",
      "split_file_000018.txt\n",
      "split_file_000019.txt\n",
      "split_file_000020.txt\n",
      "split_file_000021.txt\n",
      "split_file_000022.txt\n",
      "split_file_000023.txt\n",
      "split_file_000024.txt\n",
      "split_file_000025.txt\n",
      "split_file_000026.txt\n",
      "split_file_000027.txt\n",
      "split_file_000028.txt\n",
      "split_file_000029.txt\n",
      "split_file_000030.txt\n",
      "split_file_000031.txt\n",
      "split_file_000032.txt\n",
      "split_file_000033.txt\n",
      "split_file_000034.txt\n",
      "split_file_000035.txt\n",
      "split_file_000036.txt\n",
      "split_file_000037.txt\n",
      "split_file_000038.txt\n",
      "split_file_000039.txt\n",
      "split_file_000040.txt\n",
      "split_file_000041.txt\n",
      "split_file_000042.txt\n",
      "split_file_000043.txt\n",
      "split_file_000044.txt\n",
      "split_file_000045.txt\n",
      "split_file_000046.txt\n",
      "split_file_000047.txt\n",
      "split_file_000048.txt\n",
      "split_file_000049.txt\n",
      "split_file_000050.txt\n",
      "split_file_000051.txt\n",
      "split_file_000052.txt\n",
      "split_file_000053.txt\n",
      "split_file_000054.txt\n",
      "split_file_000055.txt\n",
      "split_file_000056.txt\n",
      "split_file_000057.txt\n",
      "split_file_000058.txt\n",
      "split_file_000059.txt\n",
      "split_file_000060.txt\n",
      "split_file_000061.txt\n",
      "split_file_000062.txt\n",
      "split_file_000063.txt\n",
      "split_file_000064.txt\n",
      "split_file_000065.txt\n",
      "split_file_000066.txt\n",
      "split_file_000067.txt\n",
      "split_file_000068.txt\n",
      "split_file_000069.txt\n",
      "split_file_000070.txt\n",
      "split_file_000071.txt\n",
      "split_file_000072.txt\n",
      "split_file_000073.txt\n",
      "split_file_000074.txt\n",
      "split_file_000075.txt\n",
      "split_file_000076.txt\n",
      "split_file_000077.txt\n",
      "split_file_000078.txt\n",
      "split_file_000079.txt\n",
      "split_file_000080.txt\n",
      "split_file_000081.txt\n",
      "split_file_000082.txt\n",
      "split_file_000083.txt\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for element in collection['elements']:\n",
    "\n",
    "    element_name = element['element_identifier']\n",
    "\n",
    "    print(element_name)\n",
    "\n",
    "    element_id = element['object']['id']\n",
    "    data = gi.datasets.download_dataset(element_id, maxwait = 3)\n",
    "    df = pd.read_csv(StringIO(data.decode(\"utf-8\")), sep=\"\\t\")\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "    # # get only species\n",
    "    # df = df.loc[(df.iloc[:,3] == \"S\")]\n",
    "\n",
    "    # #set taxa as index without space\n",
    "    # df.index = df.iloc[:,5].str.replace(\" \",\"\")\n",
    "\n",
    "    # # get only abundance for the sample\n",
    "    # df = df.iloc[:,0]\n",
    "\n",
    "    # df.name = element_name\n",
    "\n",
    "    # dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   (mgtC) Mg2+ transport protein [MgtBC (VF0106)] [Salmonella enterica subsp. enterica serovar Typhimurium str. LT2]\n",
       "1                                   (mgtB) Mg2+ transport protein [MgtBC (VF0106)] [Salmonella enterica subsp. enterica serovar Typhimurium str. LT2]\n",
       "2                                  (misL) putative autotransporter [MisL (VF0397)] [Salmonella enterica subsp. enterica serovar Typhimurium str. LT2]\n",
       "3                            (lpfA) long polar fimbria protein LpfA [Lpf (VF0105)] [Salmonella enterica subsp. enterica serovar Typhimurium str. LT2]\n",
       "4                 (lpfB) long polar fimbrial chaperone protein LpfB [Lpf (VF0105)] [Salmonella enterica subsp. enterica serovar Typhimurium str. LT2]\n",
       "                                                                           ...                                                                       \n",
       "92                              (kpsS) capsule polysaccharide modification protein [Capsule (VF0323)] [Campylobacter jejuni subsp. jejuni NCTC 11168]\n",
       "93                                       (fliL) flagellar basal body protein FliL [Flagella (VF0114)] [Campylobacter jejuni subsp. jejuni NCTC 11168]\n",
       "94                                                               (flaA) flagellin [Flagella (VF0114)] [Campylobacter jejuni subsp. jejuni NCTC 11168]\n",
       "95    (pseE/maf5) motility accessory factor PseE [Pse5Ac7Ac Pse5Ac7Am Pse8OAc Pse5Am7AcGlnAc (AI151)] [Campylobacter jejuni subsp. jejuni NCTC 11168]\n",
       "96    (pseD/maf2) motility accessory factor PseD [Pse5Ac7Ac Pse5Ac7Am Pse8OAc Pse5Am7AcGlnAc (AI151)] [Campylobacter jejuni subsp. jejuni NCTC 11168]\n",
       "Name: PRODUCT, Length: 8174, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.concat(dfs, join=\"outer\", axis = 0)\n",
    "main_df[\"species\"] = main_df[\"PRODUCT\"]\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "main_df[\"species\"] =df[\"PRODUCT\"].str.extract(r'TODO')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
